{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "paragraph = \"\"\"My favorite book is a captivating mystery thriller that blends fiction with suspense and intrigue. Each chapter unravels secrets and twists that keep me guessing. The characters are complex, the plot is unpredictable, and the tension never fades. It’s a thrilling journey that I couldn’t put down until the end.\"\"\"\n",
    "\n",
    "lower_text = paragraph.lower()\n",
    "clean_text = lower_text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "word_tokens = word_tokenize(clean_text)\n",
    "sentence_tokens = sent_tokenize(clean_text)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in word_tokens if word not in stop_words]\n",
    "\n",
    "fdist = FreqDist(filtered_words)\n",
    "\n",
    "print(\"\\nOriginal Text:\\n\", paragraph)\n",
    "print(\"\\nCleaned Text:\\n\", clean_text)\n",
    "print(\"\\nSentence Tokens:\\n\", sentence_tokens)\n",
    "print(\"\\nWord Tokens:\\n\", word_tokens)\n",
    "print(\"\\nFiltered Words (No Stopwords):\\n\", filtered_words)\n",
    "print(\"\\nWord Frequency:\\n\")\n",
    "fdist.plot(10, title=\"Word Frequency Distribution (Excluding Stopwords)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "paragraph = \"\"\"My favorite book is a captivating mystery thriller that blends fiction with suspense and intrigue. Each chapter unravels secrets and twists that keep me guessing. The characters are complex, the plot is unpredictable, and the tension never fades. It’s a thrilling journey that I couldn’t put down until the end.\"\"\"\n",
    "\n",
    "lower_text = paragraph.lower()\n",
    "clean_text = lower_text.translate(str.maketrans('', '', string.punctuation))\n",
    "word_tokens = word_tokenize(clean_text)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in word_tokens if word not in stop_words]\n",
    "\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(\"Word, PorterStemmer, LancasterStemmer, Lemmatizer\")\n",
    "print(\"-\" * 70)\n",
    "for word in filtered_words:\n",
    "    porter_stem = porter.stem(word)\n",
    "    lancaster_stem = lancaster.stem(word)\n",
    "    lemma = lemmatizer.lemmatize(word)  \n",
    "    print(word + \", \" + porter_stem + \", \" + lancaster_stem + \", \" + lemma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"\"\"My favorite book is a captivating mystery thriller that blends fiction with suspense and intrigue. Each chapter unravels secrets and twists that keep me guessing. The characters are complex, the plot is unpredictable, and the tension never fades. It’s a thrilling journey that I couldn’t put down until the end.\"\"\"\n",
    "\n",
    "words_more_than_5 = re.findall(r'\\b\\w{6,}\\b', text)\n",
    "\n",
    "numbers = re.findall(r'\\b\\d+\\b', text)\n",
    "\n",
    "capitalized_words = re.findall(r'\\b[A-Z][a-z]*\\b', text)\n",
    "\n",
    "only_alpha_words = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "\n",
    "words_starting_with_vowels = re.findall(r'\\b[aeiouAEIOU]\\w*', text)\n",
    "\n",
    "print(\"Words with more than 5 letters:\", words_more_than_5)\n",
    "print(\"Numbers in text:\", numbers if numbers else \"None found\")\n",
    "print(\"Capitalized words:\", capitalized_words)\n",
    "print(\"Words with only alphabets:\", only_alpha_words)\n",
    "print(\"Words starting with vowels:\", words_starting_with_vowels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"\"\"My favorite book is a captivating mystery thriller that blends fiction with suspense and intrigue. \n",
    "Each chapter unravels secrets and twists that keep me guessing. The characters are complex, the plot is unpredictable, \n",
    "and the tension never fades. It’s a thrilling journey that I couldn’t put down until the end. \n",
    "Contact me at example@mail.com or visit https://www.example.com. Call 123-456-7890 or +91 9876543210 for more info.\"\"\"\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    pattern = r\"\\b\\w+(?:[-']\\w+)*\\b|\\d+\\.\\d+|\\d+\"\n",
    "    return re.findall(pattern, text)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b', '<EMAIL>', text) \n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '<URL>', text)        \n",
    "    text = re.sub(r'(\\+?\\d{1,3}[\\s-]?)?\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4}', '<PHONE>', text)  \n",
    "    return text\n",
    "cleaned_text = clean_text(text)\n",
    "tokens = custom_tokenizer(cleaned_text)\n",
    "\n",
    "print(\"Cleaned Text:\\n\", cleaned_text)\n",
    "print(\"\\nCustom Tokens:\\n\", tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
